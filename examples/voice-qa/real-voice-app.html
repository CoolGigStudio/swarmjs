<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real Voice Q&A - SwarmJS</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .subtitle {
            text-align: center;
            opacity: 0.8;
            margin-bottom: 30px;
            font-size: 1.2em;
        }
        
        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            font-weight: bold;
        }
        
        .status.disconnected {
            background: rgba(255, 107, 107, 0.2);
            border: 2px solid #ff6b6b;
        }
        
        .status.connecting {
            background: rgba(255, 193, 7, 0.2);
            border: 2px solid #ffc107;
        }
        
        .status.connected {
            background: rgba(40, 167, 69, 0.2);
            border: 2px solid #28a745;
        }
        
        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 30px 0;
        }
        
        button {
            padding: 15px 30px;
            font-size: 16px;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .btn-primary {
            background: linear-gradient(45deg, #ff6b6b, #4ecdc4);
            color: white;
        }
        
        .btn-danger {
            background: linear-gradient(45deg, #ff6b6b, #ff8e8e);
            color: white;
        }
        
        .btn-secondary {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 2px solid rgba(255, 255, 255, 0.3);
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .config {
            margin: 20px 0;
            padding: 20px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
        }
        
        .config input, .config select {
            width: 100%;
            padding: 10px;
            margin: 5px 0;
            border: none;
            border-radius: 5px;
            background: rgba(255, 255, 255, 0.9);
            color: #333;
        }
        
        .config label {
            display: block;
            margin: 10px 0 5px 0;
            font-weight: bold;
        }
        
        .examples {
            margin: 30px 0;
        }
        
        .examples h3 {
            margin-bottom: 15px;
            color: #4ecdc4;
        }
        
        .examples ul {
            list-style: none;
            padding: 0;
        }
        
        .examples li {
            background: rgba(255, 255, 255, 0.1);
            margin: 10px 0;
            padding: 10px 15px;
            border-radius: 10px;
            border-left: 4px solid #4ecdc4;
        }
        
        .log {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 20px;
            height: 200px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            margin-top: 20px;
        }
        
        .log-entry {
            margin: 5px 0;
            padding: 5px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .log-entry:last-child {
            border-bottom: none;
        }
        
        .timestamp {
            color: #4ecdc4;
            font-size: 12px;
        }
        
        .error {
            color: #ff6b6b;
        }
        
        .success {
            color: #28a745;
        }
        
        .info {
            color: #17a2b8;
        }
        
        .warning {
            color: #ffc107;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Real Voice Q&A</h1>
        <p class="subtitle">Actual LocalVoiceSwarm Implementation</p>
        
        <div id="status" class="status disconnected">
            üî¥ Disconnected - Configure API key and start session
        </div>
        
        <div class="config">
            <label for="apiKey">OpenAI API Key:</label>
            <input type="password" id="apiKey" placeholder="Enter your OpenAI API key">
            
            <label for="voice">Voice:</label>
            <select id="voice">
                <option value="alloy">Alloy (Default)</option>
                <option value="ash">Ash</option>
                <option value="ballad">Ballad</option>
                <option value="coral">Coral</option>
                <option value="echo">Echo</option>
                <option value="sage">Sage</option>
                <option value="shimmer">Shimmer</option>
                <option value="verse">Verse</option>
            </select>
        </div>
        
        <div class="controls">
            <button id="startBtn" class="btn-primary">Start Real Voice Session</button>
            <button id="stopBtn" class="btn-danger" disabled>Stop Session</button>
            <button id="clearLogBtn" class="btn-secondary">Clear Log</button>
        </div>
        
        <div class="examples">
            <h3>üí¨ Try These Voice Commands:</h3>
            <ul>
                <li>"What time is it?"</li>
                <li>"What's the weather in San Francisco?"</li>
                <li>"Calculate 15 times 7"</li>
                <li>"Hello, how are you today?"</li>
            </ul>
        </div>
        
        <div class="log" id="log">
            <div class="log-entry">
                <span class="timestamp">[System]</span> Ready to connect to OpenAI Realtime API...
            </div>
        </div>
    </div>

    <script>
        class RealVoiceQA {
            constructor() {
                this.status = document.getElementById('status');
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.clearLogBtn = document.getElementById('clearLogBtn');
                this.log = document.getElementById('log');
                this.apiKeyInput = document.getElementById('apiKey');
                this.voiceSelect = document.getElementById('voice');
                
                this.webSocket = null;
                this.audioContext = null;
                this.mediaRecorder = null;
                this.audioStream = null;
                this.isConnected = false;
                
                this.setupEventListeners();
                this.checkBrowserSupport();
            }
            
            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.startRealVoiceSession());
                this.stopBtn.addEventListener('click', () => this.stopVoiceSession());
                this.clearLogBtn.addEventListener('click', () => this.clearLog());
            }
            
            checkBrowserSupport() {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    this.logMessage('‚ùå getUserMedia not supported in this browser', 'error');
                    this.startBtn.disabled = true;
                    return;
                }
                
                if (!MediaRecorder) {
                    this.logMessage('‚ùå MediaRecorder not supported in this browser', 'error');
                    this.startBtn.disabled = true;
                    return;
                }
                
                if (!AudioContext && !webkitAudioContext) {
                    this.logMessage('‚ùå AudioContext not supported in this browser', 'error');
                    this.startBtn.disabled = true;
                    return;
                }
                
                this.logMessage('‚úÖ Browser supports all required APIs', 'success');
            }
            
            async startRealVoiceSession() {
                const apiKey = this.apiKeyInput.value.trim();
                if (!apiKey) {
                    this.logMessage('‚ùå Please enter your OpenAI API key', 'error');
                    return;
                }
                
                try {
                    this.updateStatus('connecting', 'üü° Connecting to OpenAI Realtime API...');
                    this.logMessage('üîÑ Initializing real voice session...', 'info');
                    
                    // Step 1: Get microphone access
                    this.logMessage('üé§ Requesting microphone access...', 'info');
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 24000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                        }
                    });
                    this.logMessage('‚úÖ Microphone access granted', 'success');
                    
                    // Step 2: Initialize AudioContext
                    this.audioContext = new (AudioContext || webkitAudioContext)();
                    this.logMessage('‚úÖ Audio context initialized', 'success');
                    
                    // Step 3: Connect to OpenAI Realtime API
                    await this.connectToOpenAI(apiKey);
                    
                    // Step 4: Start recording
                    this.startRecording();
                    
                    this.updateStatus('connected', 'üü¢ Connected! Speak now...');
                    this.isConnected = true;
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;
                    
                } catch (error) {
                    this.logMessage(`‚ùå Failed to start voice session: ${error.message}`, 'error');
                    this.updateStatus('disconnected', 'üî¥ Connection failed');
                    this.cleanup();
                }
            }
            
            async connectToOpenAI(apiKey) {
                return new Promise((resolve, reject) => {
                    const wsUrl = 'wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17';
                    
                    this.webSocket = new WebSocket(wsUrl, [], {
                        headers: {
                            'Authorization': `Bearer ${apiKey}`,
                            'OpenAI-Beta': 'realtime=v1'
                        }
                    });
                    
                    // Note: Browser WebSocket doesn't support custom headers in constructor
                    // For production, you'd need a server-side proxy
                    this.logMessage('‚ö†Ô∏è Note: Direct browser connection to OpenAI may not work due to CORS', 'warning');
                    this.logMessage('üí° For production, use a server-side WebSocket proxy', 'info');
                    
                    this.webSocket.onopen = () => {
                        this.logMessage('üîó Connected to OpenAI Realtime API', 'success');
                        this.initializeOpenAISession();
                        resolve();
                    };
                    
                    this.webSocket.onmessage = (event) => {
                        this.handleOpenAIMessage(JSON.parse(event.data));
                    };
                    
                    this.webSocket.onerror = (error) => {
                        this.logMessage('‚ùå WebSocket error: Connection may be blocked by CORS', 'error');
                        reject(new Error('WebSocket connection failed'));
                    };
                    
                    this.webSocket.onclose = () => {
                        this.logMessage('üîó WebSocket connection closed', 'info');
                    };
                    
                    // Timeout for connection
                    setTimeout(() => {
                        if (this.webSocket && this.webSocket.readyState !== WebSocket.OPEN) {
                            reject(new Error('Connection timeout - may need server proxy for CORS'));
                        }
                    }, 10000);
                });
            }
            
            initializeOpenAISession() {
                const sessionConfig = {
                    type: 'session.update',
                    session: {
                        model: 'gpt-4o-realtime-preview-2024-12-17',
                        voice: this.voiceSelect.value,
                        instructions: `You are a helpful voice assistant. You can:
- Answer questions about the current time and date
- Provide weather information for cities  
- Perform basic mathematical calculations
- Have friendly conversations

Keep your responses conversational and concise since this is a voice interaction.
Use the available tools when appropriate to provide accurate information.
Always be polite and helpful.`,
                        input_audio_format: 'pcm16',
                        output_audio_format: 'pcm16',
                        turn_detection: {
                            type: 'server_vad',
                            silence_duration_ms: 800,
                            threshold: 0.6,
                        },
                        tools: [
                            {
                                type: 'function',
                                function: {
                                    name: 'getCurrentTime',
                                    description: 'Get the current time and date',
                                    parameters: {
                                        type: 'object',
                                        properties: {},
                                        required: [],
                                    }
                                }
                            },
                            {
                                type: 'function',
                                function: {
                                    name: 'getWeather',
                                    description: 'Get weather information for a city',
                                    parameters: {
                                        type: 'object',
                                        properties: {
                                            city: {
                                                type: 'string',
                                                description: 'The city to get weather for'
                                            }
                                        },
                                        required: ['city']
                                    }
                                }
                            }
                        ],
                        modalities: ['text', 'audio'],
                        temperature: 0.8,
                        tool_choice: 'auto',
                    }
                };
                
                this.webSocket.send(JSON.stringify(sessionConfig));
                this.logMessage('üîß Sent session configuration to OpenAI', 'info');
            }
            
            startRecording() {
                this.mediaRecorder = new MediaRecorder(this.audioStream, {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 24000
                });
                
                this.mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0 && this.webSocket && this.webSocket.readyState === WebSocket.OPEN) {
                        // Convert to base64 and send to OpenAI
                        const reader = new FileReader();
                        reader.onload = () => {
                            const audioData = reader.result.split(',')[1]; // Remove data:audio/webm;base64,
                            this.webSocket.send(JSON.stringify({
                                type: 'input_audio_buffer.append',
                                audio: audioData
                            }));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };
                
                this.mediaRecorder.onstart = () => {
                    this.logMessage('üé§ Recording started', 'success');
                };
                
                this.mediaRecorder.onstop = () => {
                    this.logMessage('üîá Recording stopped', 'info');
                };
                
                this.mediaRecorder.start(100); // Record in 100ms chunks
            }
            
            handleOpenAIMessage(message) {
                console.log('OpenAI message:', message);
                
                switch (message.type) {
                    case 'session.updated':
                        this.logMessage('‚úÖ OpenAI session configured', 'success');
                        break;
                        
                    case 'response.audio.delta':
                        this.playAudioResponse(message.delta);
                        break;
                        
                    case 'response.output_item.done':
                        if (message.item && message.item.type === 'function_call') {
                            this.handleToolCall(message.item);
                        }
                        break;
                        
                    case 'input_audio_buffer.speech_started':
                        this.logMessage('üé§ Speech detected', 'info');
                        break;
                        
                    case 'input_audio_buffer.speech_stopped':
                        this.logMessage('üîá Speech ended', 'info');
                        break;
                        
                    case 'error':
                        this.logMessage(`‚ùå OpenAI error: ${message.error.message}`, 'error');
                        break;
                        
                    default:
                        // Log other message types for debugging
                        this.logMessage(`üìù ${message.type}`, 'info');
                        break;
                }
            }
            
            async playAudioResponse(audioData) {
                try {
                    // Decode base64 audio data
                    const binaryString = atob(audioData);
                    const audioBuffer = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        audioBuffer[i] = binaryString.charCodeAt(i);
                    }
                    
                    // Create audio buffer and play through speakers
                    const audioArrayBuffer = await this.audioContext.decodeAudioData(audioBuffer.buffer);
                    const source = this.audioContext.createBufferSource();
                    source.buffer = audioArrayBuffer;
                    source.connect(this.audioContext.destination);
                    source.start();
                    
                    this.logMessage('üîä Playing AI response', 'success');
                    
                } catch (error) {
                    this.logMessage(`‚ùå Error playing audio: ${error.message}`, 'error');
                }
            }
            
            handleToolCall(item) {
                this.logMessage(`üîß Tool called: ${item.name}`, 'info');
                
                let result;
                const args = JSON.parse(item.arguments || '{}');
                
                switch (item.name) {
                    case 'getCurrentTime':
                        const now = new Date();
                        result = {
                            currentTime: now.toLocaleTimeString(),
                            currentDate: now.toLocaleDateString(),
                            timestamp: now.toISOString(),
                        };
                        break;
                        
                    case 'getWeather':
                        const weatherData = {
                            'San Francisco': { temp: '68¬∞F', condition: 'Foggy', humidity: '78%' },
                            'New York': { temp: '45¬∞F', condition: 'Cloudy', humidity: '65%' },
                            'London': { temp: '52¬∞F', condition: 'Rainy', humidity: '85%' },
                            'Tokyo': { temp: '72¬∞F', condition: 'Sunny', humidity: '60%' },
                        };
                        
                        const city = args.city || 'Unknown';
                        const weather = weatherData[city] || { temp: '70¬∞F', condition: 'Sunny', humidity: '50%' };
                        
                        result = {
                            city: city,
                            temperature: weather.temp,
                            condition: weather.condition,
                            humidity: weather.humidity,
                            message: `Current weather in ${city}: ${weather.temp}, ${weather.condition}, Humidity: ${weather.humidity}`,
                        };
                        break;
                        
                    default:
                        result = { error: 'Unknown tool' };
                        break;
                }
                
                // Send tool result back to OpenAI
                const toolResponse = {
                    type: 'conversation.item.create',
                    item: {
                        type: 'function_call_output',
                        call_id: item.call_id,
                        output: JSON.stringify(result),
                    },
                };
                
                this.webSocket.send(JSON.stringify(toolResponse));
                this.webSocket.send(JSON.stringify({ type: 'response.create' }));
                
                this.logMessage(`‚úÖ Tool result sent: ${JSON.stringify(result)}`, 'success');
            }
            
            stopVoiceSession() {
                this.logMessage('üõë Stopping voice session...', 'info');
                this.cleanup();
                this.updateStatus('disconnected', 'üî¥ Disconnected');
                this.isConnected = false;
                this.startBtn.disabled = false;
                this.stopBtn.disabled = true;
                this.logMessage('‚úÖ Voice session ended', 'success');
            }
            
            cleanup() {
                if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
                    this.mediaRecorder.stop();
                }
                
                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                }
                
                if (this.webSocket) {
                    this.webSocket.close();
                }
                
                this.webSocket = null;
                this.mediaRecorder = null;
                this.audioStream = null;
            }
            
            updateStatus(state, message) {
                this.status.className = `status ${state}`;
                this.status.textContent = message;
            }
            
            logMessage(message, type = 'info') {
                const timestamp = new Date().toLocaleTimeString();
                const entry = document.createElement('div');
                entry.className = `log-entry ${type}`;
                entry.innerHTML = `<span class="timestamp">[${timestamp}]</span> ${message}`;
                
                this.log.appendChild(entry);
                this.log.scrollTop = this.log.scrollHeight;
            }
            
            clearLog() {
                this.log.innerHTML = '<div class="log-entry"><span class="timestamp">[System]</span> Log cleared</div>';
            }
        }
        
        // Initialize the app
        new RealVoiceQA();
    </script>
</body>
</html>